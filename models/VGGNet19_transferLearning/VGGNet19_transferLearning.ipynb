{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 01:10:16.823750: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 01:10:16.823793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 01:10:16.824837: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 01:10:16.831403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 01:10:17.506368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kayaba_attribution/miniconda3/envs/tf/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.23) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "2024-03-11 01:10:18.626172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:18.653701: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:18.654274: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All requiremetns met. Using TF with GPU: NVIDIA GeForce GTX 1660 (1x)\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 01:10:18.756915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: X: 61540, y: 61540 | Validation size: X: 15385, y: 15385 | Test size: X: 35195, y: 35195 | \n",
      "Total size: X: 112120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 01:10:19.078018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.078277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.078476: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.157784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.157976: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.158090: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-03-11 01:10:19.158193: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 01:10:19.158309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3685 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Required</th>\n",
       "      <th>Installed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9.17 (main, Jul  5 2023, 20:41:20) \\n[GCC 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pip</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nvidia-smi</td>\n",
       "      <td>450.51.06</td>\n",
       "      <td>535.54.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cuda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>release 12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>2.3.0</td>\n",
       "      <td>2.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPUs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Package   Required                                          Installed\n",
       "0      Python        3.7  3.9.17 (main, Jul  5 2023, 20:41:20) \\n[GCC 11...\n",
       "1         pip       20.2                                             23.2.1\n",
       "2  nvidia-smi  450.51.06                                          535.54.03\n",
       "3        cuda       11.0                                       release 12.2\n",
       "4  tensorflow      2.3.0                                             2.15.0\n",
       "5        GPUs          1                                                  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import deeplake\n",
    "from time import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = [14, 14]\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "# Requirements taken from https://www.tensorflow.org/install/pip#linux\n",
    "python_version = sys.version\n",
    "pip_version = pip.__version__\n",
    "nvidia_smi_version = os.popen('nvidia-smi --query-gpu=driver_version --format=csv,noheader').read().strip()\n",
    "cuda_version = os.popen('nvcc --version').read().split('\\n')[3].split(',')[1].strip()\n",
    "tensorflow_version = tf.__version__\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "num_gpus = len(physical_devices)\n",
    "gpu_model = os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read().strip()\n",
    "\n",
    "req_xray_data = pd.DataFrame({\n",
    "    'Package': ['Python', 'pip', 'nvidia-smi', 'cuda', 'tensorflow', 'GPUs'],\n",
    "    'Required': ['3.7', '20.2', '450.51.06', '11.0', '2.3.0', '1'],\n",
    "    'Installed': [python_version, pip_version, nvidia_smi_version, cuda_version, tensorflow_version, num_gpus]\n",
    "})\n",
    "               \n",
    "print(f'All requiremetns met. Using TF with GPU: {gpu_model} ({num_gpus}x)')\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Lambda, Input, GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import keras\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/kayaba_attribution/Documents/UoL/FINAL_PROJECT/Code/nih-chest')\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from dataset import train_ds, val_ds, test_ds, y_test, y_val, ALL_LABELS, IMG_SIZE\n",
    "from reportUtils import generate_report\n",
    "\n",
    "MODEL_NAME = 'VGGNET16_TL'\n",
    "\n",
    "req_xray_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "outputs = Dense(len(ALL_LABELS), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                7695      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14722383 (56.16 MB)\n",
      "Trainable params: 7695 (30.06 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, f\"{MODEL_NAME}_model.png\", show_shapes=True, show_layer_names=True)\n",
    "weight_path=f\"{MODEL_NAME}_weights.best.hdf5\".format('Basic_CNN')\n",
    "\n",
    "# https://keras.io/api/callbacks/model_checkpoint/\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weight_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only = True)\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "earlystop = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 1e-4,\n",
    "    patience = 5,\n",
    "    mode = 'min', \n",
    "    restore_best_weights = True,\n",
    "    verbose = 1)\n",
    "\n",
    "# https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_delta=1e-4,\n",
    "    cooldown=1,\n",
    "    min_lr=1e-6)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, reduceLROnPlat]\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=keras.losses.BinaryCrossentropy(label_smoothing=0.0), \n",
    "                metrics=[\n",
    "                    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                    keras.metrics.Precision(name='precision'),\n",
    "                    keras.metrics.Recall(name='recall'),\n",
    "                    keras.metrics.AUC(name='auc', multi_label=True)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if weight checkpoint exists\n",
    "# if os.path.exists(weight_path):\n",
    "#     print(\"Loading weights from:\", weight_path)\n",
    "#     model.load_weights(weight_path)\n",
    "# else:\n",
    "#     print(\"No weights found, starting training from scratch.\")\n",
    "\n",
    "# start = time()\n",
    "# history = model.fit(\n",
    "#                     train_ds,\n",
    "#                     epochs=8,\n",
    "#                     validation_data=val_ds,\n",
    "#                     callbacks=callbacks_list\n",
    "#                     )\n",
    "# print('\\nTraining took {} sec'.format((time()-start)))\n",
    "# model.save(f\"{MODEL_NAME}.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
